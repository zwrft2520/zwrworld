# 第 1 章：编程与 AI 基础

## AI的主要分支

1.机器学习(Machine Learning):使计算机能够从数据中学习，而无需明确编程。
2.深度学习(DeepLearning):基于人工神经网络的机器学习子集，能处理更复杂的数据模式。
3.自然语言处理(NLP):使计算机能够理解、解释和生成人类语言。
4.计算机视觉(Computer Vision):使计算机能够"看到"并理解视觉信息。
5.机器人学(Robotics):研究设计、构建和操作机器人的学科。

## 大语言模型(LLM)的简单原理与能力

大语言模型(Large Language Models，简称LLM)是近年来AI领域最令人瞩目的进展之一。它们是基于深度学习的模型，通过分析大量文本数据学习语言模式和知识。

### LLM的基本原理

1.预训练-微调范式:
预训练:模型在大量通用文本上进行训练，学习语言的基本结构和知识。
微调:在特定任务的数据集上进一步训练，使模型适应特定领域或任务。

2.Transformer架构:
大多数现代LLM基于Transformer架构，这是一种特别适合处理序列数据的神经网络结构。Transformer的核心是自注意力机制，使模型能够捕捉句子中不同单词之间的关系。

3.大规模参数:
现代LLM通常包含数十亿甚至数千亿参数。
参数越多，模型的能力通常越强，但训练和运行成本也越高。

4.自监督学习:
LLM主要通过预测下一个单词或填补缺失单词等任务进行训练。
这种方法不需要人工标注的数据，能够利用互联网上海量的文本资源。

## LLM的能力

1.文本生成:创建各种类型的文本，从简短回复到长篇文章。
2.问答:回答基于事实或推理的问题。
3.翻译:在不同语言之间翻译文本。
4.摘要:提取长文本的关键信息，生成简洁摘要。
5.代码生成:生成和解释编程代码，如面试鸭平台上的编程题解析功能。

6.对话:进行连贯、有上下文的对话。
7.创意写作:创作故事、诗歌等创意内容。
8.情感分析:识别文本中表达的情感和态度。
9.内容分类:将文本分类到不同的主题或类别。
10.推理与逻辑:解决需要逻辑推理的问题。


## LLM 的局限性

尽管功能强大，LLM仍有一些问题:
1.可能产生幻觉:生成看似合理但实际上不正确的信息。
2.上下文窗口有限:一次只能处理有限长度的文本。
3.缺乏最新信息:仅基于训练数据，无法获取训练后的新信息(除非通过特殊方法如网络搜索进行增强)。
4.可能存在偏见:可能反映训练数据中的偏见和刻板印象。
5.对敏感内容的过滤不完善:可能需要额外的安全措施。

## 常见AI术语解析

提示词(Prompt)
提示词是用户向AI模型提供的输入文本，用于指导模型生成期望的输出。一个好的提示词可以显著提高模型输出的质量和相关性

### 模型(Model)

AI模型是经过训练的算法，能够执行特定任务。在LLM的上下文中，模型指的是如GPT-4、Claude或Llama等大型语言模型。

### 标记(Token)

标记是LLM处理文本的基本单位。一个标记可能是一个单词、单词的一部分或标点符号。理解标记对于管理模型输入限制和成本计算很重要
例如，英文中"Spring AIframework"可能被分为["Spring","Al","framework"]三个标记，而中文"Spring AI框架"可能被分为["Spring"，"Al"，"框架"]三个标记。

### 嵌入 (Embedding)

嵌入是将文本、图像等数据转换为密集的数值向量，使AI系统能够处理和理解这些数据。文本嵌入在搜索、推荐系统和文本分类中特别有用。

### 温度(Temperature)

温度是控制AI生成文本随机性的参数。较低的温度(接近0)会产生更确定性、保守的输出，而较高的温度(接近1或更高)会产生更多样化、创造性的输出。

### 微调(Fine-tuning)

微调是指在通用预训练模型的基础上，使用特定领域的数据进一步训练，使模型更适合特定任务或领域的过程。

### 上下文窗口(ContextWindow)

上下文窗口是指模型一次能处理的最大标记数。它限制了用户可以提供的输入长度和模型可以生成的输出长度的总和。

### 推理(Inference)

推理是指模型使用其学到的模式处理新输入并生成输出的过程。对于LLM，这通常指的是生成文本的过程。

### RAG(检索增强生成)

RAG是一种将检索系统与文本生成模型结合的技术，使模型能够访问和利用外部知识源，提高生成内容的准确性和相关性。
